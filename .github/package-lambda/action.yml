name: 'Package Lambda'
description: 'Packages a Lambda function and uploads it to S3'
inputs:
  s3_bucket_name:
    description: 'S3 bucket name'
    required: true
  key_prefix:
    description: 'Prefix for the S3 key (e.g., "slack-error-notifier")'
    required: true
  python_version:
    description: 'Python version to use when installing dependencies (e.g., "3.12")'
    required: false
    default: '3.12'
  build_directory:
    description: 'Directory containing the Lambda function code'
    required: true
  build_env:
    description: 'JSON array of environment variables to use during build, format: [{"name": "VAR_NAME", "value": "value"}]'
    required: false
    default: '[]'
  filter_pattern:
    description: 'JSON array of patterns to check for changed files'
    required: true
  aws_access_key_id:
    description: 'AWS Access Key ID'
    required: true
  aws_secret_access_key:
    description: 'AWS Secret Access Key'
    required: true
  github_token:
    description: 'GitHub token with permissions to read workflow runs'
    required: true
  pat:
    description: 'Personal Access Token for Git operations'
    required: true
  username:
    description: 'Git username for Git operations'
    required: true
  email:
    description: 'Git email for Git operations'
    required: true

outputs:
  s3_key:
    description: "The S3 object key of the uploaded Lambda package"
    value: ${{ steps.package-or-use.outputs.s3_key }}

runs:
  using: "composite"
  steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Configure Git # Required because we are using submodules
      shell: bash
      run: |
        git config --global user.email "${{ inputs.email }}"
        git config --global user.name "${{ inputs.username }}"
        git config --global url.https://${{ inputs.pat }}@github.com/.insteadOf https://github.com/

    - name: Checkout submodules
      shell: bash
      run: git submodule update --init --recursive

    - name: Filter Changed Files
      uses: dorny/paths-filter@v3
      id: filter
      with:
        base: ${{ github.ref }}
        ref: ${{ github.ref }}
        filters: |
          source_changes:
            ${{ inputs.filter_pattern }}

    - name: Check Previous Run Status
      id: check-status
      shell: bash
      env:
        GH_TOKEN: ${{ inputs.github_token }}
      run: |
        # Use helper script to determine if the previous run failed. Failures in the script should not fail the build.
        bash .github/package-lambda/check-previous-run.sh \
          --repo "${{ github.repository }}" \
          --branch "${{ github.ref_name }}" \
          --run-id "${{ github.run_id }}" \
          --key-prefix "${{ inputs.key_prefix }}" >> $GITHUB_OUTPUT || echo "previous_failed=false" >> $GITHUB_OUTPUT

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ inputs.aws_access_key_id }}
        aws-secret-access-key: ${{ inputs.aws_secret_access_key }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Check for Existing Package
      id: check-package
      shell: bash
      run: |
        # Determine environment tag and S3 prefix using helper script
        eval "$(bash .github/package-lambda/determine-env-and-key.sh --branch \"${{ github.ref_name }}\" --key-prefix \"${{ inputs.key_prefix }}\" --sha \"${{ github.sha }}\")"
        # List objects in S3 with the given prefix
        LATEST_PACKAGE=$(aws s3api list-objects-v2 \
          --bucket ${{ inputs.s3_bucket_name }} \
          --prefix "$s3_prefix" \
          --query "sort_by(Contents, &LastModified)[-1].Key" \
          --output text || echo "")
          
        if [ "$LATEST_PACKAGE" != "None" ] && [ -n "$LATEST_PACKAGE" ]; then
          echo "has_existing_package=true" >> $GITHUB_OUTPUT
          echo "latest_package_key=$LATEST_PACKAGE" >> $GITHUB_OUTPUT
        else
          echo "has_existing_package=false" >> $GITHUB_OUTPUT
        fi

    - name: Setup Python
      uses: actions/setup-python@v4
      if: |
        steps.filter.outputs.source_changes == 'true' || 
        steps.check-package.outputs.has_existing_package == 'false' || 
        steps.check-status.outputs.previous_failed == 'true'
      with:
        python-version: ${{ inputs.python_version }}

    - name: Package or Use Existing Lambda
      id: package-or-use
      shell: bash
      run: |
        # Compute env tag and S3 key using helper script
        eval "$(bash .github/package-lambda/determine-env-and-key.sh --branch \"${{ github.ref_name }}\" --key-prefix \"${{ inputs.key_prefix }}\" --sha \"${{ github.sha }}\")"
        S3_KEY="$s3_key"
        S3_URI="s3://${{ inputs.s3_bucket_name }}/$S3_KEY"
        
        if [[ "${{ steps.filter.outputs.source_changes }}" == "true" ]] || \
           [[ "${{ steps.check-package.outputs.has_existing_package }}" == "false" ]] || \
           [[ "${{ steps.check-status.outputs.previous_failed }}" == "true" ]]; then
          echo "Building new Lambda package..."
          
          # Create a temporary directory for packaging
          TEMP_DIR=$(mktemp -d)
          
          # Export build environment variables (if any) using helper script
          source .github/package-lambda/export-build-env.sh --json "${{ inputs.build_env }}"
          
          # Copy Lambda code to the temp directory
          cp -r ${{ inputs.build_directory }}/* $TEMP_DIR/
          
          # Navigate to the build directory
          cd $TEMP_DIR
          
          # Create ZIP package (Add any build steps needed here)
          if [ -f "package.json" ]; then
            # For Node.js projects
            npm install --production
          elif [ -f "requirements.txt" ]; then
            # For Python projects
            echo "Installing Python dependencies with Python ${{ inputs.python_version }}..."
            python -m pip install --upgrade pip
            python -m pip install -r requirements.txt -t .
          fi
          
          # Create the ZIP file
          zip -r lambda_package.zip ./* -x "*.git*" "*__pycache__*" "*.pytest_cache*" "*.venv*"
          
          # Upload to S3
          aws s3 cp lambda_package.zip $S3_URI
          
          # Clean up
          rm -rf $TEMP_DIR
          
          echo "s3_key=$S3_KEY" >> $GITHUB_OUTPUT
        else
          echo "Using existing Lambda package..."
          echo "s3_key=${{ steps.check-package.outputs.latest_package_key }}" >> $GITHUB_OUTPUT
        fi 